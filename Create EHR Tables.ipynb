{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE EHR TABLES**\n",
    "\n",
    "**AUTHOR:** Anna Zink \n",
    "\n",
    "**DATE:** April 23, 2024\n",
    "\n",
    "**DESCRIPTION:** Pull EHR data for people with survey (ideally access survey).\n",
    "  Include some limits (e.g., don't include super historic records). Note that access survey \n",
    "  is taken between 2018 and 2023. We are going to use a 2-year lookback window max, so we'll pull data from 2016-2023. Few advantages here: \n",
    "  we are pulling in less data, don't want to have access survesy so disconnected (in time) from answers, \n",
    "  coding shifts from icd-9 to icd-10. \n",
    "  Note, keeping some of these tables pretty sparse (e.g., for medications, not including whether it is common from a prescription or a fill, just if there is a record of it.) \n",
    "\n",
    "**EHR tables:**\n",
    "- condition_occurence{_ext}\n",
    "- procedure_occurence{_ext}\n",
    "- drug_exposure{_ext}\n",
    "- measurement{_ext}\n",
    "- visit_occurence{_ext}\n",
    "- person\n",
    "- (maybe) visit_detail\n",
    "- (maybe) specimen\n",
    "- (maybe) observation\n",
    "\n",
    "**UPDATES**\n",
    "\n",
    "August 21, 2025 - Add in drug classes\n",
    "\n",
    "August 18, 2025 - add triglycerides \n",
    "\n",
    "January 29, 2025 - add in A1C values and additional concept IDs\n",
    "\n",
    "Feb 5, 2025 - update for v8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BILLING_PROJECT_ID <- Sys.getenv('GOOGLE_PROJECT')\n",
    "CDR <- Sys.getenv('WORKSPACE_CDR')\n",
    "MY_BUCKET <- Sys.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(viridis)    # A nice color scheme for plots.\n",
    "library(ggthemes)   # Common themes to change the look and feel of plots.\n",
    "library(scales)     # Graphical scales map data to aesthetics in plots.\n",
    "library(skimr)      # Better summaries of data.\n",
    "library(lubridate)  # Date library from the tidyverse.\n",
    "library(bigrquery)  # BigQuery R client.\n",
    "library(tidyverse)  # Data wrangling packages.\n",
    "library(data.table) # data.table is good for handling large datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "load_data<-function(file, folder){\n",
    "    my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "    system(paste0(\"gsutil cp \", my_bucket, folder, file, \" .\"), intern=T)\n",
    "    dsn <- read_csv(file, show_col_types = FALSE)\n",
    "    return(dsn)\n",
    "}\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "# folder = \"/ehr/\" \n",
    "write_csv<-function(df, fn, folder) {\n",
    "   my_dataframe <- df\n",
    "   destination_filename <- fn\n",
    "   write_excel_csv(my_dataframe, destination_filename)\n",
    "   my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "   system(paste0(\"gsutil cp ./\", destination_filename, \" \", my_bucket, folder), intern=T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Demographics\n",
    "Pull from \"person\" table data on gender, age, race, ethnicity\n",
    "gendere_concept_id\n",
    "year_of_birth\n",
    "month_of_birth\n",
    "date_of_birth\n",
    "race_concept_id\n",
    "ethnicity_concept_id\n",
    "gender_concept_id\n",
    "sex_at_birth_concept_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pull condition data \n",
    "get_demo_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        c.CONCEPT_NAME AS GENDER,\n",
    "        a.YEAR_OF_BIRTH,\n",
    "        a.MONTH_OF_BIRTH,\n",
    "        a.DAY_OF_BIRTH,\n",
    "        d.CONCEPT_NAME AS RACE,\n",
    "        e.CONCEPT_NAME AS ETHNICITY\n",
    "    FROM\n",
    "        `person` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `concept` c on a.GENDER_CONCEPT_ID = c.CONCEPT_ID\n",
    "         LEFT JOIN `concept` d on a.RACE_CONCEPT_ID = d.CONCEPT_ID\n",
    "         LEFT JOIN `concept` e on a.ETHNICITY_CONCEPT_ID = e.CONCEPT_ID\n",
    "        \", sep=\"\")\n",
    "\n",
    "ehr_demo_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"demographics_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_demo_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_demo_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check if file is in the bucket\n",
    "# Get the bucket name\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "system(paste0(\"gsutil ls \", my_bucket, \"/bq_exports/azink@researchallofus.org/ehr/demographics_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "demo_ehr <- read_bq_export_from_workspace_bucket(ehr_demo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_csv(demo_ehr, 'demographics.csv', \"/survey/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mortality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pull condition data \n",
    "get_death_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.DEATH_DATE, \n",
    "        c.concept_name as DEATH_TYPE, \n",
    "        d.concept_name as DEATH_CAUSE\n",
    "    FROM\n",
    "        `death` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%'  and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `concept` c on a.DEATH_TYPE_CONCEPT_ID = c.CONCEPT_ID\n",
    "         LEFT JOIN `concept` d on a.CAUSE_CONCEPT_ID = d.CONCEPT_ID\n",
    "        \", sep=\"\")\n",
    "\n",
    "ehr_death_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"death_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_death_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_death_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "death_ehr <- read_bq_export_from_workspace_bucket(ehr_death_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "death_ehr$DEATH_YEAR<-year(death_ehr$DEATH_DATE)\n",
    "table(death_ehr$DEATH_YEAR, useNA=\"always\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_csv(death_ehr, 'mortality.csv', \"/ehr/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Conditions\n",
    "Pull from \"condition_occurence\" fieds:\n",
    "- condition_occurrence_id (*link to ext for source id*)\n",
    "- person_id\n",
    "- condition_concept_id (*link to concept table for description*)\n",
    "- condition_start_date\n",
    "- condition_end_date\n",
    "- condition_source_value\n",
    "- condition_source_concept_id (*link to concept table for description*)\n",
    "\n",
    "and from \"condition_occurrence_ext\" fields:\n",
    "- condition_occurrence_id\n",
    "- src_id \n",
    "\n",
    "subset to people in ehr and survey data using the \"cb_search_person\":\n",
    "- has_ehr_data = 1\n",
    "- has_ppi_survey_data = 1\n",
    "\n",
    "Either want to link up to the visit_occurrence table so we know if it was an ed visit, hospitalization, etc.\n",
    "all seem to link with the \"visit_occurence_id\" OR\n",
    "keep visit occurence id in and then link after transferred to workspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pull condition data \n",
    "get_conditions_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.CONDITION_CONCEPT_ID,\n",
    "        a.CONDITION_START_DATE,\n",
    "        a.CONDITION_END_DATE,\n",
    "        a.CONDITION_SOURCE_VALUE,\n",
    "        a.CONDITION_SOURCE_CONCEPT_ID,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS CONDITION_NAME,\n",
    "        e.CONCEPT_NAME AS SOURCE\n",
    "    FROM\n",
    "        `condition_occurrence` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `condition_occurrence_ext` c on a.condition_occurrence_id = c.condition_occurrence_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.condition_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.condition_source_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.CONDITION_START_DATE) >= 2016\n",
    "        \", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "\n",
    "ehr_conditions_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"conditions_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "#bq_table_save(\n",
    "#  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_conditions_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "#  ehr_conditions_path,\n",
    "#  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "conditions_ehr <- read_bq_export_from_workspace_bucket(ehr_conditions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "names(conditions_ehr)\n",
    "keepvars<-c('PERSON_ID','CONDITION_CONCEPT_ID','CONDITION_NAME','CONDITION_START_DATE','VISIT_OCCURRENCE_ID','SRC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head(conditions_ehr[,keepvars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conditions_ehr$year<-year(conditions_ehr$CONDITION_START_DATE)\n",
    "table(conditions_ehr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "for (yr in seq(2023, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-conditions_ehr[conditions_ehr$year == yr, keepvars]\n",
    "    write_csv(subset, paste0(\"conditions_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# peep files\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "system(paste0(\"gsutil ls \", my_bucket, \"/ehr/conditions_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Procedures\n",
    "\n",
    "Update conditions sql for procedures, following same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_procedures_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.PROCEDURE_CONCEPT_ID,\n",
    "        a.PROCEDURE_DATE,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS CONDITION_NAME,\n",
    "        e.CONCEPT_NAME AS SOURCE\n",
    "    FROM\n",
    "        `procedure_occurrence` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                  WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `procedure_occurrence_ext` c on a.procedure_occurrence_id = c.procedure_occurrence_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.procedure_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.procedure_source_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.PROCEDURE_DATE) >= 2016\n",
    "        \", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ehr_procedures_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"procedures_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_procedures_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_procedures_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to delete files\n",
    "#my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "#system(paste0(\"gsutil rm \", my_bucket, \"/bq_exports/azink@researchallofus.org/ehr/procedures_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "procedures_ehr <- read_bq_export_from_workspace_bucket(ehr_procedures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "procedures_ehr$year<-year(procedures_ehr$PROCEDURE_DATE)\n",
    "table(procedures_ehr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "for (yr in seq(2022, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-procedures_ehr[procedures_ehr$year == yr,]\n",
    "    write_csv(subset, paste0(\"procedures_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug_exposure\n",
    "\n",
    "Update conditions sql for drug exposures, following same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_drugs_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.DRUG_CONCEPT_ID,\n",
    "        a.DRUG_EXPOSURE_START_DATE,\n",
    "        a.DRUG_EXPOSURE_END_DATE, \n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS DRUG_NAME\n",
    "    FROM\n",
    "        `drug_exposure` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `drug_exposure_ext` c on a.drug_exposure_id = c.drug_exposure_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.drug_concept_id \n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.DRUG_EXPOSURE_START_DATE) >= 2016 \n",
    "        \", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_drugs_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"drugs_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files. - only need to run once\n",
    "#bq_table_save(\n",
    "#  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_drugs_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "# ehr_drugs_path,\n",
    "#  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "drugs_ehr <- read_bq_export_from_workspace_bucket(ehr_drugs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_ehr$year<-year(drugs_ehr$DRUG_EXPOSURE_START_DATE)\n",
    "table(drugs_ehr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "for (yr in seq(2023, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-drugs_ehr[drugs_ehr$year == yr,]\n",
    "    write_csv(subset, paste0(\"drugs_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create crosswalk of drugs to drug classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_drug_classes_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.DRUG_CONCEPT_ID,\n",
    "        b.ANCESTOR_CONCEPT_ID, \n",
    "        d.CONCEPT_NAME AS DRUG_CLASS,\n",
    "        d.VOCABULARY_ID, \n",
    "        d.CONCEPT_CLASS_ID\n",
    "    FROM\n",
    "        (SELECT DISTINCT DRUG_CONCEPT_ID FROM `drug_exposure`) a\n",
    "         JOIN `concept_ancestor` b on a.drug_concept_id = b.descendant_concept_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = b.ancestor_concept_id \n",
    "    WHERE\n",
    "        d.standard_concept = 'C' AND d.domain_id = 'Drug'\n",
    "        \", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_classes_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"drug_classes_*.csv\")\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files. - only need to run once\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_drug_classes_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  drug_classes_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "drug_class <- read_bq_export_from_workspace_bucket(drug_classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc<-drug_class[grepl('ATC', drug_class$CONCEPT_CLASS_ID),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(atc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse multiple concept class id\n",
    "atc_updt <- atc %>% select(CONCEPT_CLASS_ID, DRUG_CLASS, DRUG_CONCEPT_ID) %>% \n",
    "    group_by(CONCEPT_CLASS_ID, DRUG_CONCEPT_ID) %>% \n",
    "    summarize( atc_class = ifelse(n_distinct(DRUG_CLASS) > 1,\n",
    "                       \"multiple classes\",\n",
    "                       first(DRUG_CLASS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_wide <- atc_updt %>% select(CONCEPT_CLASS_ID, atc_class, DRUG_CONCEPT_ID) %>%\n",
    "  mutate(CONCEPT_CLASS_ID = gsub(\" \", \"_\", CONCEPT_CLASS_ID)) %>%  # replace spaces with underscores\n",
    "  pivot_wider(names_from = CONCEPT_CLASS_ID, values_from = atc_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(unique(atc_wide$ATC_2nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(atc_wide, 'atc_classes.csv',\"/ehr/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement\n",
    "\n",
    "There are LOTS of measurements. With the new data, too many to pull in. Going to separate out large files by measurement type\n",
    "- heart rate (hr_YYYY.csv)\n",
    "- blood pressure (bp_YYY.csv)\n",
    "- respiratory rate (rr_YYYY.csv)\n",
    "- other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get heart rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# heart rate query \n",
    "get_hr_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.MEASUREMENT_CONCEPT_ID,\n",
    "        a.MEASUREMENT_DATE,\n",
    "        a.VALUE_AS_NUMBER,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS MEASUREMENT,\n",
    "        e.CONCEPT_NAME AS UNIT\n",
    "    FROM\n",
    "        `measurement` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `measurement_ext` c on a.measurement_id = c.measurement_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.measurement_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.unit_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.MEASUREMENT_DATE) >= 2016\n",
    "        AND A.MEASUREMENT_CONCEPT_ID in (3027018)\n",
    "        \", sep=\"\")\n",
    "\n",
    "ehr_hr_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"hr_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN ONCE\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "#bq_table_save(\n",
    "#  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_hr_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "#  ehr_hr_path,\n",
    "#  destination_format = \"CSV\")\n",
    "\n",
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "hr <- read_bq_export_from_workspace_bucket(ehr_hr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hr$year<-year(hr$MEASUREMENT_DATE)\n",
    "table(hr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "keepvars<-c('MEASUREMENT','MEASUREMENT_CONCEPT_ID','PERSON_ID','VISIT_OCCURRENCE_ID','MEASUREMENT_DATE','VALUE_AS_NUMBER', 'UNIT','year')\n",
    "for (yr in seq(2022, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-hr[hr$year == yr,keepvars]\n",
    "    write_csv(subset, paste0(\"hr_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Pressure Readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp <- bq_table_download(bq_project_query(\n",
    "    BILLING_PROJECT_ID, page_size = 25000,\n",
    "    query = str_glue('\n",
    "SELECT\n",
    "  a.measurement_concept_id,\n",
    "  b.concept_name,\n",
    "  count(*) as n\n",
    "FROM\n",
    " `{CDR}.measurement` a\n",
    " join `{CDR}.concept` b on a.measurement_concept_id = b.concept_id\n",
    "WHERE\n",
    "        EXTRACT(YEAR FROM MEASUREMENT_DATE) >= 2016 \n",
    "        AND upper(b.concept_name) like \"%SYSTOLIC BLOOD PRESSURE%\" or\n",
    "            upper(b.concept_name) like \"%DIASTOLIC BLOOD PRESSURE%\"\n",
    "GROUP BY \n",
    " a.measurement_concept_id,\n",
    " b.concept_name\n",
    "ORDER BY\n",
    " n desc\n",
    "LIMIT 20\n",
    "')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude invasive measures of blood pressure\n",
    "bp$flag<-ifelse(grepl('INVASIVE', toupper(bp$concept_name)), 1, 0)\n",
    "bp$flag<-ifelse(grepl('ANESTHESIA', toupper(bp$concept_name)), 1, bp$flag)\n",
    "bp$flag<-ifelse(grepl('ARTERY', toupper(bp$concept_name)), 1, bp$flag)\n",
    "bp\n",
    "bp_ids<-bp[bp$flag == 0, 'measurement_concept_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(as.list(bp_ids), collapse=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blood pressure query \n",
    "get_bp_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.MEASUREMENT_CONCEPT_ID,\n",
    "        a.MEASUREMENT_DATE,\n",
    "        a.VALUE_AS_NUMBER,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS MEASUREMENT,\n",
    "        e.CONCEPT_NAME AS UNIT\n",
    "    FROM\n",
    "        `measurement` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `measurement_ext` c on a.measurement_id = c.measurement_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.measurement_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.unit_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.MEASUREMENT_DATE) >= 2016\n",
    "        AND A.MEASUREMENT_CONCEPT_ID in (3012888, 3004249, 4154790, 4152194, 3034703, 3018586, \n",
    "        903115, 903118, 3028737, 44789316, 44789315, 4248524, 4232915, 3019962, 3009395)\n",
    "        \", sep=\"\")\n",
    "\n",
    "ehr_bp_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"bp_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN ONCE\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_bp_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_bp_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "bp <- read_bq_export_from_workspace_bucket(ehr_bp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp$year<-year(bp$MEASUREMENT_DATE)\n",
    "table(bp$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "keepvars<-c('MEASUREMENT','MEASUREMENT_CONCEPT_ID','PERSON_ID','VISIT_OCCURRENCE_ID','MEASUREMENT_DATE','VALUE_AS_NUMBER', 'UNIT','year')\n",
    "for (yr in seq(2023, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-bp[bp$year == yr,keepvars]\n",
    "    write_csv(subset, paste0(\"bp_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "# system(paste0(\"gsutil ls \", my_bucket, \"/ehr/bp_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Respiratory Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rr <- bq_table_download(bq_project_query(\n",
    "    BILLING_PROJECT_ID, page_size = 25000,\n",
    "    query = str_glue('\n",
    "SELECT\n",
    "  a.measurement_concept_id,\n",
    "  b.concept_name,\n",
    "  count(*) as n\n",
    "FROM\n",
    " `{CDR}.measurement` a\n",
    " join `{CDR}.concept` b on a.measurement_concept_id = b.concept_id\n",
    "WHERE\n",
    "        EXTRACT(YEAR FROM MEASUREMENT_DATE) >= 2016 \n",
    "        AND A.MEASUREMENT_CONCEPT_ID in (3024171, 4313591)\n",
    "GROUP BY \n",
    " a.measurement_concept_id,\n",
    " b.concept_name\n",
    "ORDER BY\n",
    " n desc\n",
    "LIMIT 20\n",
    "')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# repiratory rate query \n",
    "get_rr_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.MEASUREMENT_CONCEPT_ID,\n",
    "        a.MEASUREMENT_DATE,\n",
    "        a.VALUE_AS_NUMBER,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS MEASUREMENT,\n",
    "        e.CONCEPT_NAME AS UNIT\n",
    "    FROM\n",
    "        `measurement` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `measurement_ext` c on a.measurement_id = c.measurement_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.measurement_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.unit_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.MEASUREMENT_DATE) >= 2016\n",
    "        AND A.MEASUREMENT_CONCEPT_ID in (3024171, 4313591)\n",
    "        \", sep=\"\")\n",
    "\n",
    "ehr_rr_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"rr_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN ONCE\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_rr_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_rr_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "rr <- read_bq_export_from_workspace_bucket(ehr_rr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rr$year<-year(rr$MEASUREMENT_DATE)\n",
    "table(rr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "keepvars<-c('MEASUREMENT','MEASUREMENT_CONCEPT_ID','PERSON_ID','VISIT_OCCURRENCE_ID','MEASUREMENT_DATE','VALUE_AS_NUMBER', 'UNIT','year')\n",
    "for (yr in seq(2021, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-rr[rr$year == yr,keepvars]\n",
    "    write_csv(subset, paste0(\"rr_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other\n",
    "\n",
    "Include: oxygen sat, BMI, calcium, creatinine, glucose, hemoglobin, potassium, chloride, sodium, urea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 20 measurements (there is so much data to pull in otherwise)\n",
    "t<- bq_table_download(bq_project_query(\n",
    "    BILLING_PROJECT_ID, page_size = 25000,\n",
    "    query = str_glue('\n",
    "SELECT\n",
    "  a.measurement_concept_id,\n",
    "  b.concept_name,\n",
    "  count(*) as n\n",
    "FROM\n",
    " `{CDR}.measurement` a\n",
    " join `{CDR}.concept` b on a.measurement_concept_id = b.concept_id\n",
    "WHERE\n",
    "        EXTRACT(YEAR FROM MEASUREMENT_DATE) >= 2016 \n",
    "GROUP BY \n",
    " a.measurement_concept_id,\n",
    " b.concept_name\n",
    "ORDER BY\n",
    " n desc\n",
    "LIMIT 20\n",
    "')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_measurements_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.MEASUREMENT_CONCEPT_ID,\n",
    "        a.MEASUREMENT_DATE,\n",
    "        a.VALUE_AS_NUMBER,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        e.CONCEPT_NAME AS UNIT, \n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS MEASUREMENT\n",
    "    FROM\n",
    "        `measurement` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `measurement_ext` c on a.measurement_id = c.measurement_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.measurement_concept_id \n",
    "         LEFT JOIN `concept` e on e.concept_id = a.unit_concept_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.MEASUREMENT_DATE) >= 2016\n",
    "        AND A.MEASUREMENT_CONCEPT_ID IN (40762499, 3025315,\n",
    "             3038553, 3004501, 3023103, 3019550, 3013682, 3016723, 3014576, 3006906,\n",
    "             3000963, 3004410, 3005673, 2212392, 4197971, 3034639, 4184637, 3007263, 2212393,\n",
    "            42869630, 40762352, 36304734, 3003309, 3034962, 3000483, 3024629, 3005131, 3039896, 3011424,\n",
    "            3014053, 3004077, 3037110, 3020399, 3033408,3022192,4017787)\n",
    "        \", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_msrs_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"msrs_*.csv\")\n",
    "\n",
    "# ONLY NEED TO RUN ONCE\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_measurements_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_msrs_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete files\n",
    "#my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "#system(paste0(\"gsutil rm \", my_bucket, \"/bq_exports/azink@researchallofus.org/ehr/drugs_*.csv\"), intern=T)\n",
    "\n",
    "# to peep files\n",
    "#my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "#system(paste0(\"gsutil ls \", my_bucket, \"/bq_exports/azink@researchallofus.org/ehr/msrs_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "msrs_ehr <- read_bq_export_from_workspace_bucket(ehr_msrs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrs_ehr$year<-year(msrs_ehr$MEASUREMENT_DATE)\n",
    "table(msrs_ehr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "keepvars<-c('MEASUREMENT','MEASUREMENT_CONCEPT_ID','PERSON_ID','VISIT_OCCURRENCE_ID','MEASUREMENT_DATE','VALUE_AS_NUMBER', 'UNIT','year')\n",
    "for (yr in seq(2016, 2018)) {\n",
    "    print(yr)\n",
    "    subset<-msrs_ehr[msrs_ehr$year == yr,keepvars]\n",
    "    write_csv(subset, paste0(\"msrs_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visit Occurrence\n",
    "\n",
    "Pull in visit type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_visits_sql <- paste(\"\n",
    "    SELECT\n",
    "        a.PERSON_ID,\n",
    "        a.VISIT_OCCURRENCE_ID,\n",
    "        a.VISIT_CONCEPT_ID,\n",
    "        a.VISIT_START_DATE,\n",
    "        a.VISIT_END_DATE, \n",
    "        c.SRC_ID,\n",
    "        d.CONCEPT_NAME AS VISIT_TYPE\n",
    "    FROM\n",
    "        `visit_occurrence` a\n",
    "         JOIN (SELECT DISTINCT a.PERSON_ID FROM `cb_search_all_events` a \n",
    "                   join `cb_search_person` b on a.PERSON_ID = b.PERSON_ID\n",
    "                WHERE b.has_ehr_data = 1  \n",
    "                 AND  (concept_id IN (SELECT distinct concept_id FROM `cb_criteria` \n",
    "                 WHERE path LIKE '%3000000694%' and is_standard = 0 AND is_selectable = 1)) \n",
    "         ) b on a.person_id = b.person_id \n",
    "         LEFT JOIN `visit_occurrence_ext` c on a.visit_occurrence_id = c.visit_occurrence_id\n",
    "         LEFT JOIN `concept` d on d.concept_id = a.visit_concept_id \n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM a.VISIT_START_DATE) >= 2016\n",
    "        \", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_visits_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #%strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"ehr\",\n",
    "  \"visits_*.csv\")\n",
    "\n",
    "# ONLY NEED TO RUN ONCE\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), get_visits_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  ehr_visits_path,\n",
    "  destination_format = \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "#system(paste0(\"gsutil ls \", my_bucket, \"/bq_exports/azink@researchallofus.org/ehr/visits_*.csv\"), intern=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read export into bucket \n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols()\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "visits_ehr <- read_bq_export_from_workspace_bucket(ehr_visits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_ehr$year<-year(visits_ehr$VISIT_START_DATE)\n",
    "table(visits_ehr$year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to each year and write to csv \n",
    "for (yr in seq(2020, 2023)) {\n",
    "    print(yr)\n",
    "    subset<-visits_ehr[visits_ehr$year == yr,]\n",
    "    write_csv(subset, paste0(\"visits_\", yr, \".csv\"), \"/ehr/\")\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
