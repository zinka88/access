{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARIZE ACCESS SURVEY**\n",
    "\n",
    "**AUTHOR**: Anna Zink\n",
    "\n",
    "**DATE**: April 23, 2024\n",
    "\n",
    "**Updated**: February 4, 2025 to account for v8 data\n",
    "\n",
    "**DESCRIPTION**: Pull answers to access survey and create flags for people who can't afford care or have delayed care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages \n",
    "library(plyr)\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "library(stringr)\n",
    "library(lubridate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data<-function(file, folder){\n",
    "    my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "    system(paste0(\"gsutil cp \", my_bucket, folder, file, \" .\"), intern=T)\n",
    "    dsn <- read_csv(file, show_col_types = FALSE)\n",
    "    return(dsn)\n",
    "}\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "# folder = \"/ehr/\" \n",
    "write_csv<-function(df, fn, folder) {\n",
    "   my_dataframe <- df\n",
    "   destination_filename <- fn\n",
    "   write_excel_csv(my_dataframe, destination_filename)\n",
    "   my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "   system(paste0(\"gsutil cp ./\", destination_filename, \" \", my_bucket, folder), intern=T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download access survey \n",
    "\n",
    "This code is based off the cohort builder result from searching for the access survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset \"ACCESS_SURVEY\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v8\n",
    "access_survey_sql <- paste(\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (43528895)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "access_survey_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  #strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"access_survey\",\n",
    "  \"access_survey_*.csv\")\n",
    "message(str_glue('The data will be written to {access_survey_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "\n",
    "#bq_table_save(\n",
    "#  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), access_survey_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "#  access_survey_path,\n",
    "#  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {survey_72329960_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(survey = col_character(), question = col_character(), answer = col_character(), survey_version_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "data <- read_bq_export_from_workspace_bucket(access_survey_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create flags for questions about affordability and delayed care\n",
    "\n",
    "The questions ask about the past 12 MONTHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one large \"Can't Afford Care\" bucket & \"Delayed Medical Care\" bucket \n",
    "data$afford_flag<-ifelse(grepl(\"Can't Afford Care\", data$question), 1, 0)\n",
    "data$delayed_flag<-ifelse(grepl(\"Delayed Medical Care\", data$question), 1, 0)\n",
    "data$healthcare_int_flag<-ifelse(grepl(\"Spoken To Professional\", data$question), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure flags are flagging the questions we would expect them to\n",
    "data %>% group_by(question, afford_flag, delayed_flag, healthcare_int_flag) %>% summarize(n=length(person_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$ans<-str_split(data$answer, ':', simplify = TRUE)[,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$ans_yes<-ifelse(trimws(data$ans) == \"Yes\", 1, 0)\n",
    "data$ans_yes<-ifelse(data$afford_flag ==1 & trimws(data$ans) == \"Very Worried\", 1, data$ans_yes)\n",
    "data$ans_no<-ifelse(trimws(data$ans) == \"No\", 1, 0)\n",
    "data$ans_dontknow<-ifelse(trimws(data$ans) == \"Dont Know\", 1, 0)\n",
    "data$skip<-ifelse(trimws(data$ans) == \"Skip\", 1, 0)\n",
    "# flag peolpe who have had a hc interaction within the year \n",
    "data$last_hc_int<-ifelse(data$healthcare_int_flag == 1 & trimws(data$ans) %in% c('6mo Or Less','6 Mo To 1 Year Ago'),\n",
    "                         'within a year', ifelse(data$healthcare_int_flag == 1 & trimws(data$ans) %in% c('1 To 2 Years Ago'),\n",
    "                         '1-2 years ago',ifelse(data$healthcare_int_flag == 1, 'other', NA)))\n",
    "data$last_hc_int_1yr<-ifelse(data$last_hc_int %in% c('within a year'), 1, 0)\n",
    "data$last_hc_int_2yr<-ifelse(data$last_hc_int %in% c('within a year','1-2 years ago'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out different reasons\n",
    "summ<-data %>% group_by(afford_flag, delayed_flag, question) %>% summarize(n=n(),n_yes=sum(ans_yes),yes=mean(ans_yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_freq<-summ[summ$delayed_flag == 1 | summ$afford_flag == 1,]\n",
    "head(access_freq)\n",
    "write_csv(access_freq, 'access_question_freq.csv', \"/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize by person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$tmp_count<-1\n",
    "byperson <- data %>% group_by(person_id) %>% summarize(\n",
    "     nobs=sum(tmp_count),\n",
    "                mindate=min(survey_datetime), \n",
    "                maxdate=max(survey_datetime),\n",
    "                nskip=sum(skip), \n",
    "                afford=sum(afford_flag*ans_yes), \n",
    "                delayed=sum(delayed_flag*ans_yes),\n",
    "                hc_int_1_yr=max(last_hc_int_1yr, na.rm=TRUE), \n",
    "                hc_int_2_yr=max(last_hc_int_2yr, na.rm=TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byperson$afford_ind<-ifelse(byperson$afford>0, 1, 0)\n",
    "byperson$delayed_ind<-ifelse(byperson$delayed>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byperson %>% group_by(afford_ind, delayed_ind) %>% summarise(hc1=mean(hc_int_1_yr), hc2=mean(hc_int_2_yr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe <- byperson\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename <- 'access_byperson.csv'\n",
    "\n",
    "# store the dataframe in current workspace\n",
    "write_excel_csv(my_dataframe, destination_filename)\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# Copy the file from current workspace to the bucket\n",
    "system(paste0(\"gsutil cp ./\", destination_filename, \" \", my_bucket, \"/survey/\"), intern=T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
